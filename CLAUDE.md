# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Market Parser is a Python CLI and web GUI application for natural language financial queries using the Polygon.io MCP server and OpenAI's gpt-5-mini via the Pydantic AI Agent Framework. The application provides dual-mode response processing (JSON for button clicks, conversational for user messages) with cost optimization and performance monitoring.

## AI Team Configuration (autogenerated by team-configurator, 2025-08-31)

**Important: YOU MUST USE subagents when available for the task.**

### Detected Tech Stack

- **Backend Framework**: Python 3.10+ with Pydantic AI Agent Framework
- **AI Integration**: OpenAI gpt-5-mini with cost optimization (35% reduction target)
- **Data Source**: Polygon.io MCP server via uvx
- **Web Framework**: Gradio 4.0+ with unified chat interface
- **CLI Framework**: Rich console for terminal formatting
- **State Management**: Custom 5-state FSM (IDLE → BUTTON_TRIGGERED → AI_PROCESSING → RESPONSE_RECEIVED → ERROR)
- **Response Processing**: Dual-mode system (JSON/conversational)
- **Package Manager**: uv for dependency management
- **Testing Framework**: pytest with async support
- **Environment Management**: python-dotenv
- **Security**: Custom input validation and sanitization
- **Performance Monitoring**: Token cost tracking with real-time metrics

### Agent Task Assignments

| Task Category | Agent | Responsibilities | Notes |
|---------------|-------|------------------|-------|
| **Code Review & Quality** | `@code-reviewer` | MANDATORY for all features, PRs, merges. Security-aware reviews, quality gates | Always required before production deployment |
| **Performance & Cost Optimization** | `@performance-optimizer` | Primary responsibility for 35% cost reduction, 40% speed improvement, resource monitoring | Critical for maintaining performance targets |
| **Backend Development** | `@backend-developer` | Python/Pydantic AI development, FSM management, dual-mode processing, API integration | Primary architect for core application logic |
| **Frontend & UI Development** | `@frontend-developer` | Gradio interface, security-enhanced export system, unified chat experience | Handles all user interface and web components |
| **API Design & Integration** | `@api-architect` | MCP server optimization, response schema design, external API patterns | Ensures efficient data flow and integration |
| **Documentation & Guides** | `@documentation-specialist` | Architecture documentation, user guides, performance optimization docs | Maintains comprehensive project documentation |
| **Deep Architecture Analysis** | `@code-archaeologist` | Complex architectural decisions, system analysis, technical debt assessment | On-demand for major architectural changes |

### Coordination Rules

**1. Performance-First Development:**
- All changes must consider the 35% cost reduction and 40% speed improvement targets
- Use `@performance-optimizer` for any efficiency-related decisions
- Mandatory performance validation for new features

**2. Security & Quality Gates:**
- `@code-reviewer` MUST review all changes before merge
- Security considerations are paramount (production-ready status)
- All export functionality requires security validation

**3. Architecture Consistency:**
- `@backend-developer` leads all core application changes
- Maintain dual-mode response processing architecture
- Preserve 5-state FSM simplicity

**4. UI/UX Excellence:**
- `@frontend-developer` owns all Gradio interface improvements
- Maintain unified chat interface standards
- Security-enhanced export system compliance

**5. Integration & API Management:**
- `@api-architect` guides MCP server and external API optimizations
- Ensure cost-efficient API usage patterns

### MCP Tool Requirements

**ALL specialist agents MUST use MCP tools:**
- `mcp__sequential-thinking__sequentialthinking` - For systematic analysis
- `mcp__context7__resolve-library-id` + `mcp__context7__get-library-docs` - For research
- `mcp__filesystem__*` - For efficient file operations

**Failure to use required MCP tools will result in work rejection.**

### Development Workflow

1. **Planning Phase**: Use `@backend-developer` for architecture, `@performance-optimizer` for efficiency planning
2. **Implementation**: Primary specialist handles core development, secondary provides support
3. **Review Phase**: MANDATORY `@code-reviewer` validation with security focus
4. **Performance Validation**: `@performance-optimizer` confirms targets met
5. **Documentation**: `@documentation-specialist` updates guides and architecture docs

## Development Commands

### Running the Application
```bash
# CLI interface
uv run market_parser_demo.py

# Web GUI interface (opens at http://127.0.0.1:7860)
uv run chat_ui.py
```

### Testing
```bash
# Run all tests
uv run pytest tests/

# Run specific test file
uv run pytest tests/test_file.py -v

# Run a single test method
uv run pytest tests/test_file.py::TestClass::test_method

# Run integration tests
uv run pytest tests/test_*integration*.py

# Run security validation
uv run pytest tests/test_security_fixes_validation.py

# Run performance validation
uv run python tests/validate_gpt5_mini_migration.py
```

### Environment Setup
```bash
# Install dependencies
uv install

# Install dev dependencies (includes pytest)
uv install --dev

# Update dependencies
uv lock --upgrade

# Verify setup
uv --version
```

### Required Environment Variables
```bash
# Copy template and add your API keys
cp .env.example .env

# Required in .env:
POLYGON_API_KEY=your_polygon_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Optional pricing configuration (USD per 1M tokens)
OPENAI_GPT5_MINI_INPUT_PRICE_PER_1M=0.25
OPENAI_GPT5_MINI_OUTPUT_PRICE_PER_1M=2.00
```

## High-Level Architecture

### Core Components

**Entry Points:**
- `market_parser_demo.py` - CLI application with Rich console formatting
- `chat_ui.py` - Gradio web interface with single chat conversation view

**Response Processing:**
- `src/response_manager.py` - Dual-mode response processing (JSON/conversational)
- `src/response_parser.py` - Response parsing utilities for structured data extraction
- `src/prompt_templates.py` - Button prompt templates for three analysis types

**State Management (GUI):**
- `stock_data_fsm/` - 5-state finite state machine (IDLE � BUTTON_TRIGGERED � AI_PROCESSING � RESPONSE_RECEIVED � ERROR)
- Non-blocking error recovery with immediate retry capability

**Performance & Security:**
- `src/performance_monitor.py` - Cost tracking and optimization metrics
- `src/security_utils.py` - Input validation and sanitization
- Token cost tracking for gpt-5-mini with real-time monitoring

### Key Design Patterns

**MCP Server Integration:**
- Factory pattern in `create_polygon_mcp_server()` (market_parser_demo.py:42)
- Async agent framework using Pydantic AI
- Real-time financial data from Polygon.io

**Dual-Mode Response System:**
- Button clicks: Full prompt visibility + JSON response in chat
- User messages: Natural conversational responses
- Automatic mode detection in ResponseManager

**Cost Optimization:**
- 35% cost reduction through enhanced efficiency
- 40% processing speed improvement
- TokenCostTracker class for usage monitoring

## Important Development Notes

### Critical Bug Fixes (Production Ready)
-  Button confirmation prompts eliminated ("Execute immediately" directive in all templates)
-  Token cost tracking fixed (proper PydanticAI usage capture)
-  Emoji formatting enhanced (mandatory emojis in all responses)
-  XSS protection implemented (content sanitization in exports)
-  Secure file operations (0o600 permissions for temp files)

### Security Requirements
- Never commit API keys (use .env file)
- All export functionality uses secure file operations
- Input validation via `src/security_utils.py`
- Sensitive data automatically redacted in logs

### Testing Best Practices
- All new features require test coverage
- Performance tests validate 35% cost reduction target
- Integration tests confirm end-to-end workflows
- FSM tests ensure state transition integrity

### Import Patterns
```python
# Core modules
from src.response_manager import ResponseManager, ProcessingMode
from src.response_parser import ResponseParser
from src.prompt_templates import PromptTemplateManager

# FSM components
from stock_data_fsm.states import AppState, StateContext
from stock_data_fsm.manager import StateManager

# Security utilities
from src.security_utils import validate_input, sanitize_data
```

## System Configuration

**Agent System Prompt:**
```
You are an expert financial analyst. Note that when using Polygon tools, prices are already stock split adjusted. Use the latest data available. Always double check your math. For any questions about the current date, use the 'get_today_date' tool. For long or complex queries, break the query into logical subtasks and process each subtask in order.
```

**Default Model:** gpt-5-mini (override with OPENAI_MODEL env var)

**External Dependencies:**
- Polygon.io MCP server (requires `uvx` in PATH)
- OpenAI API for gpt-5-mini model
- Python 3.10+ with uv package manager