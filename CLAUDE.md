# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Market Parser is a Python CLI and web GUI application for natural language financial queries using the Polygon.io MCP server and OpenAI's gpt-5-nano via the Pydantic AI Agent Framework. The application allows users to ask questions about stock market data in natural language and receive formatted responses.

## AI Team Configuration (autogenerated by team-configurator, 2025-08-17)

**Important: YOU MUST USE subagents when available for the task.**

### Detected Tech Stack (Enhanced JSON Architecture)

- **Backend Framework**: Python with Pydantic AI Agent Framework + JSON schema validation
- **Frontend Framework**: Gradio v4+ with enhanced JSON display components and real-time feedback
- **AI Integration**: OpenAI gpt-5-nano via Pydantic AI with structured JSON output optimization
- **Data Source**: Polygon.io MCP server for real-time financial market data
- **JSON Architecture**: Comprehensive schema-driven system with validation and fallback strategies
- **Data Processing**: Dual parser architecture (JSON primary, regex fallback) with confidence scoring
- **State Management**: Enhanced FSM with JSON validation states and workflow orchestration
- **Build Tools**: uv for dependency management and package execution
- **CLI Framework**: Rich console for enhanced terminal formatting and interaction
- **Test Framework**: pytest with comprehensive JSON validation and production testing suites
- **Configuration**: python-dotenv for secure environment variable management
- **Monitoring**: Advanced debug logging with JSON workflow tracking and performance metrics
- **Schema Management**: JSON Schema Draft 2020-12 compliant with versioning support
- **Data Validation**: Multi-layer validation with business rules and auto-correction capabilities
- **Debug System**: Comprehensive JSON workflow logging with error tracking and performance analysis

### Agent Task Assignments (JSON-Optimized)

| Task Category | Agent | JSON Architecture Responsibilities | Critical Notes |
|---------------|-------|----------------------------------|-----------------|
| **Code Review & Quality** | `@code-reviewer` | MANDATORY for all features, PRs, and merges. JSON schema validation, security review of parsers | Always validate JSON handling security and schema integrity |
| **Performance & Optimization** | `@performance-optimizer` | JSON parsing optimization, schema validation performance, debug logging efficiency | Focus on JSON processing speed and memory usage |
| **JSON Schema Architecture** | `@backend-developer` | JSON schema design, validation rules, parser implementation, fallback strategies | Primary agent for all JSON system components |
| **Data Validation & Parsing** | `@backend-developer` | Schema validation logic, business rules, confidence scoring, error correction | Handles JSON parsing accuracy and data integrity |
| **API Design & Integration** | `@api-architect` | JSON response schemas, MCP integration patterns, structured prompt design | Ensures JSON contracts with external services |
| **Frontend & UI Development** | `@frontend-developer` | JSON display components, real-time UI updates, enhanced data visualization | Gradio JSON textboxes and structured data displays |
| **State Management & FSM** | `@backend-developer` | JSON-aware FSM states, workflow orchestration, debug state tracking | Enhanced FSM with JSON validation integration |
| **Monitoring & Debug Systems** | `@backend-developer` | JSON debug logger, workflow tracking, performance metrics, error analysis | Comprehensive JSON workflow monitoring |
| **Documentation & Training** | `@documentation-specialist` | JSON architecture guides, schema documentation, migration procedures | JSON system usage and troubleshooting guides |
| **Testing & Validation** | `@backend-developer` | JSON schema testing, validation testing, production bug testing | Comprehensive JSON system validation |

### Specialized JSON Domain Assignments

| JSON Domain | Primary Agent | Secondary Agent | Specific Focus |
|-------------|---------------|-----------------|----------------|
| **JSON Schema Evolution** | `@backend-developer` | `@api-architect` | Schema versioning, compatibility, migration strategies |
| **Parser Architecture** | `@backend-developer` | `@performance-optimizer` | Dual parser system, fallback strategies, performance optimization |
| **Validation Workflows** | `@backend-developer` | `@code-reviewer` | Schema validation, business rules, error handling, auto-correction |
| **Debug & Monitoring** | `@backend-developer` | `@performance-optimizer` | Workflow tracking, performance metrics, error analysis |
| **UI JSON Integration** | `@frontend-developer` | `@backend-developer` | JSON textboxes, real-time displays, confidence indicators |
| **Schema Documentation** | `@documentation-specialist` | `@backend-developer` | API references, migration guides, troubleshooting docs |
| **Production Testing** | `@backend-developer` | `@code-reviewer` | JSON validation testing, integration testing, bug verification |
| **Cost Optimization** | `@performance-optimizer` | `@backend-developer` | JSON processing efficiency, validation caching, resource usage |

### Enhanced Architecture Coordination Rules

**1. JSON Schema Integrity:**
- NEVER modify schemas without `@backend-developer` involvement and `@code-reviewer` validation
- Use `@api-architect` for external contract changes affecting JSON structure
- Require comprehensive testing before schema version updates

**2. Parser System Reliability:**
- Maintain dual parser architecture (JSON + regex fallback) for maximum compatibility
- Use `@backend-developer` for primary JSON parser enhancements
- Coordinate fallback strategy changes with `@performance-optimizer`

**3. Debug & Monitoring Excellence:**
- Implement comprehensive JSON workflow logging for production troubleshooting
- Use `@backend-developer` for debug system enhancements
- Monitor performance metrics through `@performance-optimizer`

**4. UI/Backend JSON Coordination:**
- Synchronize JSON display components between `@frontend-developer` and `@backend-developer`
- Ensure real-time UI updates reflect JSON validation states
- Maintain consistent confidence scoring across UI components

### Enhanced Development Workflow (JSON-Focused)

1. **Schema Design Phase**: Use `@backend-developer` with `@api-architect` for external contract alignment
2. **Validation Implementation**: Primary `@backend-developer` with `@code-reviewer` for security validation
3. **UI Integration**: Coordinate `@frontend-developer` and `@backend-developer` for JSON display components
4. **Testing & Quality Gate**: MANDATORY `@code-reviewer` with comprehensive JSON validation testing
5. **Performance Optimization**: Use `@performance-optimizer` for JSON processing efficiency
6. **Documentation Updates**: Use `@documentation-specialist` for JSON architecture guides

### JSON Architecture Best Practices

**Schema Management:**
- Version all schemas with backward compatibility considerations
- Implement comprehensive validation with graceful error handling
- Maintain fallback strategies for production reliability

**Parser Implementation:**
- Primary JSON parser with regex fallback for maximum compatibility
- Confidence scoring for data quality assessment
- Comprehensive error handling with detailed logging

**UI Integration:**
- Real-time JSON textboxes for debugging and transparency
- Structured data displays with confidence indicators
- Enhanced loading states with progress tracking

**Monitoring & Debug:**
- Comprehensive workflow tracking with unique identifiers
- Performance metrics for optimization insights
- Error analysis with context preservation

## ⚠️ CRITICAL: Tech-Lead-Orchestrator Enforcement Protocols

**MANDATORY REQUIREMENTS FOR @tech-lead-orchestrator:**

### Agent Verification Requirements
- ❌ **NEVER fabricate agent names** - Only use agents listed in Agent Task Assignments table above
- ✅ **MUST READ this section first** - Verify agent exists before assignment
- ✅ **MUST use agents according to their defined specialties** - Respect the role boundaries

**Valid Agents ONLY:**
- `@code-reviewer` - MANDATORY for all features, PRs, and merges
- `@performance-optimizer` - Cost optimization, latency improvements, scaling
- `@backend-developer` - Python development, async patterns, FSM, testing
- `@api-architect` - MCP server integration, response schemas
- `@frontend-developer` - Gradio interface enhancements, UI/UX
- `@code-archaeologist` - Deep codebase analysis, architecture decisions
- `@documentation-specialist` - README updates, API docs, guides

### Delegation Execution Requirements
- ❌ **NEVER stop after creating delegation plan** - Must trigger execution
- ✅ **MUST provide execution trigger command** - Include specific agent invocation
- ✅ **MUST initiate delegation sequence** - Don't leave user to manually start
- ✅ **MUST include handoff instructions** - Specify what each agent should do

### Tech-Lead-Orchestrator Role Restrictions

**CRITICAL BOUNDARIES FOR @tech-lead-orchestrator:**

- ❌ **DO NOT implement any code yourself**
- ❌ **DO NOT make direct file changes**
- ❌ **DO NOT write or modify code**
- ❌ **DO NOT fabricate agent names that don't exist**
- ❌ **DO NOT reference non-existent tools**
- ❌ **DO NOT stop after planning - MUST trigger execution**
- ✅ **ONLY perform strategic analysis and create delegation plans**
- ✅ **ONLY identify which specialist agents are needed FROM CLAUDE.md**
- ✅ **ONLY provide specific handoff instructions for each delegation**
- ✅ **MUST initiate the delegation sequence you create**

**REQUIRED DELIVERABLES:**

1. **Strategic Analysis**: Brief assessment of the technical issues and fix complexity
2. **Specialist Agent Selection**: List of required agents with specific reasons
3. **Delegation Plan**: Structured task breakdown with specific agent assignments
4. **Handoff Instructions**: Exact instructions for each specialist agent
5. **Coordination Strategy**: How tasks should be sequenced and dependencies managed

**EXPECTED OUTPUT FORMAT:**

```markdown
## Strategic Analysis
[Brief technical assessment]

## Verified Specialist Agents (FROM CLAUDE.md ONLY)
- @agent-name: [specific reason and scope - VERIFIED EXISTS IN CLAUDE.md]

## Delegation Plan
### Task Group 1: [Priority Level]
- **Agent**: @agent-name (VERIFIED IN CLAUDE.md)
- **Scope**: [specific tasks]
- **Handoff**: [exact instructions referencing documented patterns]
- **Dependencies**: [prerequisites or blockers]

## Coordination Strategy
[How to execute the delegations in sequence]

## Execution Trigger
[MANDATORY: Provide the exact command to start the first delegation]
```

### Research Protocol Enforcement
- ❌ **No fictitious MCP tools** - Don't reference non-existent tools
- ✅ **Use Available Research Methods** - Use built-in analysis and reasoning capabilities
- ✅ **Document Analysis** - Read existing documentation and best practices
- ✅ **Code Pattern Research** - Analyze existing codebase patterns

### Structured Analysis Requirements
- ✅ **Apply Systematic Thinking** - Break down complex problems methodically
- ✅ **Structured Problem Solving** - Use logical step-by-step analysis
- ✅ **Thought Progression** - Document reasoning process clearly
- ✅ **Adaptive Analysis** - Adjust approach as understanding deepens

**VIOLATION CONSEQUENCES:**
- Fabricating agent names → Task rejection and re-delegation
- Stopping without execution → Manual intervention required
- Using non-existent tools → Incorrect implementation patterns

### Corrected Delegation Example
```
## Delegation Plan
### Task 1: UI Fixes (CRITICAL)
- **Agent**: @frontend-developer (VERIFIED in CLAUDE.md line 169)
- **Scope**: Fix Gradio async handlers using documented patterns
- **Handoff**: Use patterns from existing code and documentation for modern async handling
- **Dependencies**: None

## Execution Trigger
@frontend-developer: Fix the async button handlers in chat_ui.py using best practices from Gradio documentation. Apply direct function references instead of lambda wrappers.
```

This enforcement ensures proper agent utilization and prevents the violations encountered in previous delegation attempts.

## 🧠 MANDATORY ANALYSIS PROTOCOLS FOR ALL SPECIALIST AGENTS

**CRITICAL: ALL SPECIALIST AGENTS MUST FOLLOW THESE PROTOCOLS**

### 1. STRUCTURED THINKING ENFORCEMENT

**EVERY specialist agent MUST use structured analysis for:**

- 🧠 **Complex Problem Analysis**: Break down multi-step problems systematically
- 📝 **Planning Before Implementation**: Outline approach, identify risks, consider alternatives
- 🔍 **Validation and Understanding**: Confirm task requirements and expected outcomes
- ⚡ **Dependency Analysis**: Identify what needs to be done first/last
- 🎯 **Solution Verification**: Validate approach before implementation

**Required Analysis Pattern for ALL Agents:**

```markdown
## Task Analysis
### 1. Understanding the Problem
- [Clear definition of what needs to be done]
- [Current state assessment]
- [Root cause identification]

### 2. Solution Planning
- [Step-by-step implementation approach]
- [Required resources and dependencies]
- [Risk assessment and mitigation]

### 3. Implementation Strategy
- [Specific technical approaches]
- [Testing and validation plan]
- [Rollback considerations]

### 4. Success Validation
- [Measurable success criteria]
- [Testing procedures]
- [Quality verification steps]
```

## 🛠️ DEVELOPMENT WORKFLOW PROTOCOLS

**STRUCTURED APPROACH FOR ALL SPECIALIST AGENTS:**

### Standard Development Workflow

**PHASE 1: PLANNING AND ANALYSIS**
- Break down complex tasks systematically using structured analysis
- Identify dependencies and prerequisites
- Research best practices using available documentation and codebase analysis
- Plan implementation approach with risk assessment

**PHASE 2: RESEARCH AND PREPARATION**
- Review existing project documentation and patterns
- Analyze current codebase implementation conventions
- Study framework-specific best practices from official documentation
- Document findings and chosen approaches

**PHASE 3: IMPLEMENTATION**
- Apply researched patterns and best practices
- Use efficient file operations for code changes
- Implement comprehensive error handling and validation
- Follow established architectural patterns

**PHASE 4: VALIDATION AND TESTING**
- Verify implementation meets all requirements
- Test error scenarios and edge cases
- Validate integration with existing systems
- Document changes and test results

### Role-Specific Development Requirements

**@code-reviewer - MUST:**
- Perform systematic code analysis and security review
- Research latest framework best practices for validation
- Use comprehensive testing approaches for quality assurance

**@frontend-developer - MUST:**
- Research current frontend framework patterns and best practices
- Plan UI/UX implementations with user experience considerations
- Implement modern event handling and component architecture

**@backend-developer - MUST:**
- Research current backend patterns, security practices, and async handling
- Plan architecture changes with system design considerations
- Implement robust data validation and error handling

**@documentation-specialist - MUST:**
- Structure comprehensive documentation with logical organization
- Research documentation standards and best practices
- Implement clear, actionable guides with examples

### Best Practices Research Topics

**Common Research Areas for Market Parser Project:**
- **@frontend-developer**: "async handling", "event listeners", "chatbot components", "interface configuration"
- **@backend-developer**: "async patterns", "error handling", "state management", "testing frameworks"
- **@api-architect**: "API design", "response schemas", "authentication patterns", "rate limiting"
- **@code-reviewer**: "security best practices", "code quality standards", "performance patterns"
- **@performance-optimizer**: "optimization techniques", "caching strategies", "monitoring patterns"
- **@code-archaeologist**: "architecture analysis", "refactoring patterns", "technical debt assessment"
- **@documentation-specialist**: "documentation standards", "API documentation", "user guide patterns"

### 2. RESEARCH AND DOCUMENTATION MANDATE

**EVERY specialist agent MUST research best practices using:**

- 🔧 **Documentation Analysis**: Review existing project documentation and guidelines
- 📚 **Best Practices Research**: Study current standards for the technology stack
- 🔍 **Implementation Patterns**: Analyze existing codebase patterns and conventions
- 📋 **Technology Standards**: Follow established framework-specific patterns

**Required Research Approach:**
```markdown
## Research Phase
### 1. Current State Analysis
- [Review existing implementation]
- [Identify patterns and conventions]
- [Document current architecture]

### 2. Best Practices Investigation
- [Technology-specific standards]
- [Industry best practices]
- [Security considerations]

### 3. Implementation Planning
- [Chosen approach with justification]
- [Integration with existing systems]
- [Testing strategy]
```

### 3. MANDATORY TESTING PROTOCOL REQUIREMENTS

#### 🧪 CRITICAL: ALL BUG FIXES MUST INCLUDE TEST SCRIPT CREATION

**TESTING MANDATE FOR ALL SPECIALIST AGENTS:**

- ✅ **MUST create test script for every bug fix** - No exceptions
- ✅ **MUST include validation criteria** - Define what constitutes a successful fix
- ✅ **MUST test error scenarios** - Verify error handling works correctly
- ✅ **MUST validate production scenarios** - Test with real-world data and inputs
- ✅ **MUST document test procedures** - Clear instructions for running tests

**Required Test Script Structure:**

```python
#!/usr/bin/env python3
"""
Test Script for [Bug Fix Description]
Created: [Date]
Purpose: Validate fix for [specific bug]
Success Criteria: [clear criteria for pass/fail]
"""

import pytest
import asyncio
from typing import List, Dict, Any

class Test[BugFixName]:
    """Test suite for [specific bug fix]"""
    
    def setup_method(self):
        """Setup test environment before each test"""
        # Initialize test data and mock objects
        pass
    
    def test_bug_reproduction(self):
        """Reproduce the original bug to confirm it existed"""
        # This test should FAIL before the fix
        # This test should PASS after the fix
        pass
    
    def test_fix_validation(self):
        """Validate the fix works correctly"""
        # Test the specific fix implementation
        pass
    
    def test_edge_cases(self):
        """Test edge cases that could break the fix"""
        # Test boundary conditions and error scenarios
        pass
    
    def test_regression_prevention(self):
        """Ensure fix doesn't break existing functionality"""
        # Test that other features still work
        pass
    
    def test_production_scenarios(self):
        """Test with production-like data and conditions"""
        # Use real API responses, actual user inputs
        pass

def validate_fix_success() -> bool:
    """
    Run comprehensive validation of the bug fix
    Returns: True if all criteria met, False otherwise
    """
    success_criteria = [
        # Define specific measurable criteria
        "Criterion 1: [specific test]",
        "Criterion 2: [specific test]", 
        "Criterion 3: [specific test]"
    ]
    
    # Implementation of validation logic
    return all_criteria_met

if __name__ == "__main__":
    # Run the test suite
    pytest.main([__file__, "-v"])
    
    # Validate overall fix success
    if validate_fix_success():
        print("✅ BUG FIX VALIDATION: SUCCESS")
    else:
        print("❌ BUG FIX VALIDATION: FAILED")
```

**Testing Success Criteria Standards:**

- **Response Parser Fixes**: Must extract >90% of expected fields from real AI responses
- **Message History Fixes**: Zero None content entries allowed in production scenarios
- **FSM Error Recovery**: Must recover from ERROR state in <2 seconds with user feedback
- **UI Integration**: All button operations must work sequentially without errors
- **Performance**: No regression in response times or memory usage
- **JSON Schema Validation**: 100% schema compliance with fallback handling

### 4. IMPLEMENTATION QUALITY REQUIREMENTS

**ALL specialist agents MUST:**

- ✅ **Use Structured Analysis First**: Never start implementation without systematic analysis
- ✅ **Research Before Implementing**: Study best practices and existing patterns
- ✅ **Follow Modern Standards**: Use only current best practices from research
- 🛡️ **Include Comprehensive Error Handling**: Robust error management and user feedback
- 🧪 **Plan Testing Strategy**: Include validation and testing approaches
- 📋 **Document All Changes**: Clear explanations of what was changed and why
- 🧪 **Create Test Scripts**: MANDATORY test script for every bug fix
- 🔬 **Validate Success**: Demonstrate fix meets defined success criteria
- 🎯 **JSON Architecture Compliance**: Maintain dual parser compatibility
- 📊 **Performance Monitoring**: Include metrics for JSON processing efficiency

### 5. QUALITY GATES AND VERIFICATION

**Before completing any task, ALL specialist agents MUST:**

- ✅ **Verify Analysis Completeness**: Confirm structured analysis was performed
- ✅ **Validate Research**: Ensure implementation follows researched best practices
- ✅ **Test Error Scenarios**: Confirm error handling works as designed
- ✅ **Check Function Signatures**: Validate all function signatures match requirements
- ✅ **Preserve Architecture**: Ensure changes maintain existing architectural patterns
- ✅ **Address Root Causes**: Confirm fixes address identified root causes
- ✅ **NEW: Create and run test script validating the fix**
- ✅ **NEW: Document test results and success criteria met**
- ✅ **JSON SPECIFIC: Validate schema compatibility and fallback behavior**
- ✅ **JSON SPECIFIC: Verify performance metrics within acceptable thresholds**

### 6. CONSEQUENCES FOR NON-COMPLIANCE

**FAILURE TO FOLLOW THESE PROTOCOLS WILL RESULT IN:**

- ❌ **Task Rejection**: Work will be rejected and must be redone
- ❌ **Re-delegation**: Task will be reassigned to different agent
- ❌ **Quality Gate Failure**: Code will not pass review process
- ❌ **Production Risk**: Changes may cause production issues

**VERIFICATION CHECKLIST FOR ALL AGENTS:**
- [ ] Performed structured analysis of the task
- [ ] Researched best practices for the implementation
- [ ] Documented reasoning and approach
- [ ] Implemented solution using researched patterns
- [ ] Added comprehensive error handling
- [ ] Planned and documented testing approach
- [ ] Created mandatory test script for bug fixes
- [ ] Verified all requirements are met

## Development Environment

This project uses `uv` for dependency management and Python package execution. All dependencies are managed through `pyproject.toml`.

### Required Environment Variables

⚠️ **CRITICAL SECURITY REQUIREMENT**: Never commit API keys to version control.

1. **Copy the secure template:**
   ```bash
   cp .env.example .env
   ```

2. **Add your actual API keys to `.env`:**
   ```env
   POLYGON_API_KEY=your_polygon_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   # Optional: pricing for cost estimates (USD)
   OPENAI_GPT5_NANO_INPUT_PRICE_PER_1M=0.10
   OPENAI_GPT5_NANO_OUTPUT_PRICE_PER_1M=0.40
   ```

3. **Verify security:**
   ```bash
   # Ensure .env is protected
   grep -q "^.env$" .gitignore && echo "✅ Protected" || echo "❌ Security risk!"
   ```

**Security Features:**
- Input validation and sanitization via `src/security_utils.py`
- Secure logging that redacts sensitive data automatically
- Environment variable validation on startup
- See `SECURITY.md` for complete security guidelines

## Common Development Commands

### Running the Application

- **CLI interface**: `uv run market_parser_demo.py`
- **Web GUI interface**: `uv run chat_ui.py` (opens at <http://127.0.0.1:7860>)

### Testing

- **Run all tests**: `uv run pytest tests/` (pytest is in dev dependencies)
- **Run specific test**: `uv run pytest tests/test_file.py`
- **Run integration tests**: `uv run pytest tests/test_*integration*.py`
- **Run production tests**: `uv run python tests/run_production_tests.py`
- **Install dev dependencies**: `uv install --dev`

### Environment Management

- **Install dependencies**: `uv install`
- **Update dependencies**: `uv lock --upgrade`
- **Check environment**: `uv --version` and verify `.env` file exists

## Code Architecture

### Core Components

1. **market_parser_demo.py**: CLI application entry point
   - Contains `TokenCostTracker` class for usage/cost tracking
   - Implements `create_polygon_mcp_server()` factory function
   - Main async CLI loop with Rich console formatting

2. **chat_ui.py**: Enhanced Gradio web interface with comprehensive features
   - 🧠 **FSM-Driven State Management** - Robust workflow with state transitions
   - 📊 **Structured Stock Analysis** - Dedicated buttons for Snapshot, S&R, Technical Analysis  
   - 🎯 **Context-Aware Prompts** - Intelligent ticker extraction and structured prompts
   - ⏳ **Real-time Processing Status** - Loading states with step-by-step progress
   - 🛡️ **Advanced Error Handling** - User-friendly messages and graceful recovery
   - 📈 **Enhanced Data Display** - DataFrames with confidence scoring and warnings
   - 🔍 **Debug Monitoring** - FSM state tracking and system diagnostics
   - 💾 **Export Functionality** - Enhanced markdown export with detailed formatting
   - Provides chat export functionality

### Key Architectural Patterns

- **MCP Server Integration**: Uses Pydantic AI's MCP server integration to connect with Polygon.io
- **Async Agent Framework**: Built on Pydantic AI with OpenAI Responses API model
- **Cost Tracking**: Comprehensive token usage and cost tracking across sessions
- **Shared Components**: CLI and GUI share the same agent configuration and MCP server setup

### Dependencies & Technologies

- **Core Framework**: `pydantic-ai-slim[openai,mcp]` for AI agent orchestration
- **Web Interface**: `gradio>=4.0.0` for the GUI
- **CLI Formatting**: `rich` for terminal output formatting
- **Environment**: `python-dotenv` for configuration management
- **External APIs**: Polygon.io MCP server via uvx, OpenAI gpt-5-nano model

### System Prompt Configuration

The agent uses a consistent system prompt across both interfaces:

```text
"You are an expert financial analyst. Note that when using Polygon tools, prices are already stock split adjusted. Use the latest data available. Always double check your math. For any questions about the current date, use the 'get_today_date' tool. For long or complex queries, break the query into logical subtasks and process each subtask in order."
```

## File Structure

```
market-parser-polygon-mcp/
├── src/                          # Core application modules
│   ├── __init__.py
│   ├── response_parser.py        # Response parsing utilities for structured data extraction
│   ├── json_parser.py           # JSON parsing with fallback strategies
│   ├── json_schemas.py          # JSON schema definitions and validation
│   ├── prompt_templates.py      # Structured prompt templates for analysis types
│   ├── schema_validator.py      # Schema validation logic and business rules
│   ├── json_debug_logger.py     # Debug logging for JSON workflows
│   ├── security_utils.py        # Input validation and security utilities
│   └── example_json_responses.py # Example responses for testing and development
├── stock_data_fsm/              # Finite State Machine module for GUI state management
│   ├── __init__.py
│   ├── states.py                # Application states enum and context data classes
│   ├── transitions.py           # State transition rules and validation logic
│   ├── manager.py               # Main FSM controller with transition orchestration
│   └── tests/                   # FSM-specific test suite
│       ├── __init__.py
│       ├── test_states.py
│       ├── test_transitions.py
│       ├── test_manager.py
│       └── test_integration.py
├── tests/                       # Comprehensive test suite
│   ├── __init__.py
│   ├── test_integration.py      # Main integration tests
│   ├── test_actual_integration.py
│   ├── test_prompt_templates.py
│   ├── test_response_parser.py
│   ├── test_json_schemas.py
│   ├── test_production_*.py     # Production scenario tests
│   ├── run_*.py                 # Test runners and validation scripts
│   └── validate_*.py            # Fix validation scripts
├── logs/                        # Application and debug logs
│   ├── json_workflow_debug.log
│   ├── production_*.log
│   └── debug_*.log
├── scripts/                     # Utility and demonstration scripts
│   ├── debug_parser_data_sources.py
│   ├── demo_json_prompts.py
│   └── simple_test.py
├── config/                      # Configuration files (ready for future use)
├── docs/                        # Comprehensive documentation
│   ├── JSON_ARCHITECTURE_GUIDE.md
│   ├── USER_GUIDE_JSON_FEATURES.md
│   ├── TROUBLESHOOTING_JSON.md
│   ├── FEATURE_SCOPE_STOCK_DATA_GUI.md
│   ├── DEPLOYMENT_GUIDE_AWS.md
│   ├── reports/                 # Project reports and analysis
│   │   ├── README.md
│   │   ├── COMPREHENSIVE_BUG_FIX_REPORT.md
│   │   ├── JSON_RESPONSE_IMPLEMENTATION_REPORT.md
│   │   └── *.md                # Various technical reports
│   └── scratchpad.md           # Development notes
├── images/                      # Project assets and logos
│   └── logo.png
├── market_parser_demo.py        # CLI application entry point
├── chat_ui.py                   # Web GUI application (primary enhanced version)
├── pyproject.toml              # Project configuration and dependencies
├── uv.lock                     # Lock file for reproducible builds
├── README.md                   # Main project documentation
├── CLAUDE.md                   # AI agent guidance and protocols
└── SECURITY.md                 # Security guidelines and best practices
```

## Development Patterns

### MCP Server Integration
The project uses the Polygon.io MCP server via `uvx` for real-time financial data access. The `create_polygon_mcp_server()` function in `market_parser_demo.py:16` handles server initialization and connection management.

### State Management (GUI)
The `stock_data_fsm` module implements a deterministic finite state machine for robust GUI workflow management:
- States are defined in `stock_data_fsm/states.py:12` with `AppState` enum
- Transitions managed by `StateManager` class in `stock_data_fsm/manager.py:25`
- Context data flows through `StateContext` objects for stateful operations

### JSON Architecture (Enhanced)
The `src/` directory contains the enhanced JSON architecture components:
- **Schema Management**: `src/json_schemas.py` defines structured data schemas
- **Parsing Logic**: `src/json_parser.py` implements dual parser architecture (JSON + regex fallback)
- **Response Processing**: `src/response_parser.py` handles AI response extraction and validation
- **Debug Logging**: `src/json_debug_logger.py` provides comprehensive workflow tracking
- **Security**: `src/security_utils.py` ensures input validation and data sanitization

### Agent Configuration
Both CLI and GUI share identical agent setup with:
- Model: `gpt-5-nano` via OpenAI Responses API
- System prompt focused on financial analysis accuracy
- Token cost tracking via `TokenCostTracker` class

### Testing Strategy
- **Comprehensive Test Suite**: All tests organized in `tests/` directory
- **FSM Tests**: Module-specific tests in `stock_data_fsm/tests/`
- **Integration Testing**: `tests/test_integration.py` and `tests/test_actual_integration.py`
- **Production Testing**: `tests/test_production_*.py` for real-world scenario validation
- **JSON Validation**: `tests/test_json_*.py` for schema and parsing validation

### Import Patterns
With the new structure, use these import patterns:

```python
# Core modules from src/
from src.response_parser import ResponseParser
from src.prompt_templates import PromptTemplateManager
from src.json_schemas import StockDataSchema
from src.schema_validator import SchemaValidator
from src.json_debug_logger import JSONDebugLogger

# FSM components
from stock_data_fsm.states import AppState, StateContext
from stock_data_fsm.manager import StateManager
from stock_data_fsm.transitions import StateTransitions

# Security utilities
from src.security_utils import validate_input, sanitize_data
```

## Future Development

The `docs/FEATURE_SCOPE_STOCK_DATA_GUI.md` contains detailed specifications for planned GUI enhancements including:

- Structured data display components
- Finite State Machine architecture for button-triggered actions
- Technical indicator displays
- Support/resistance level visualization

When implementing new features, refer to existing patterns in the shared agent configuration and cost tracking systems.

## Important Development Notes

- **Environment Setup**: Create `.env` file with required API keys before running applications (see template in Required Environment Variables section)
- **External Dependencies**: The Polygon.io MCP server requires `uvx` to be available in the system PATH
- **Architecture Preservation**: All file modifications during development should preserve the FSM state management patterns and JSON architecture integrity
- **Cost Tracking**: Token cost tracking is enabled by default - check `TokenCostTracker` usage when adding new agent interactions
- **Model Configuration**: Default model is `gpt-5-nano` but can be overridden via `OPENAI_MODEL` environment variable
- **Testing Requirements**: Run tests from project root using `uv run pytest tests/` for the main test suite
- **JSON Architecture**: Follow dual parser patterns in `src/json_parser.py` for reliability and fallback handling