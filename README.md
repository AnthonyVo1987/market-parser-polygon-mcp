# Market Parser with Polygon MCP Server

![Project Logo](images/logo.png)

A simple Python CLI for natural language financial queries using the [Polygon.io](https://polygon.io/) [MCP server](https://github.com/polygon-io/mcp_polygon) and OpenAI `gpt-5-nano` via the [Pydantic AI Agent Framework](https://ai.pydantic.dev/agents/).

## Features

- **Ask questions like:**
  - `Tesla price now`
  - `AAPL volume last week`
  - `Show me the price of MSFT on 2023-01-01`

- **Rich CLI output:**
  Answers are formatted for easy reading in your terminal.

## Disclaimer

**Warning:** The examples, demos, and outputs produced with this project are generated by artificial intelligence and large language models. You acknowledge that this project and any outputs are provided "AS IS", may not always be accurate and may contain material inaccuracies even if they appear accurate because of their level of detail or specificity, outputs may not be error free, accurate, current, complete, or operate as you intended, you should not rely on any outputs or actions without independently confirming their accuracy, and any outputs should not be treated as financial or legal advice. You remain responsible for verifying the accuracy, suitability, and legality of any output before relying on it.

---

## Quickstart (with [uv](https://github.com/astral-sh/uv))

1. **Install [uv](https://github.com/astral-sh/uv) if you don't have it:**

   ```sh
   curl -Ls https://astral.sh/uv/install.sh | sh
   ```

2. **Get your API keys:**
   - [Polygon.io API key](https://polygon.io/)
   - [OpenAI API key](https://platform.openai.com/)

3. **Create a `.env` at the project root (recommended):**

   ```env
   POLYGON_API_KEY=your_polygon_api_key_here
   OPENAI_API_KEY=your_openai_api_key_here
   # Optional: pricing for cost estimates (USD)
   OPENAI_GPT5_NANO_INPUT_PRICE_PER_1M=0.10
   OPENAI_GPT5_NANO_OUTPUT_PRICE_PER_1M=0.40
   ```

4. **Run the CLI (dependencies will be auto-installed from `pyproject.toml`):**

   ```sh
   uv run market_parser_demo.py
   ```

5. **Type your question and press Enter!**

   Type `exit` to quit.

---

## Chatbot GUI (Optional)

You can also use a web-based Chatbot GUI (Gradio) that runs the same agent and MCP server.

- Install deps (already in `pyproject.toml`): `gradio`
- Run the GUI:

  ```sh
  uv run chat_ui.py
  ```
  
  **Features Available in Web UI:**
  - ðŸ§  **FSM-Driven State Management** - Robust workflow management  
  - ðŸ“Š **Structured Data Analysis** - Stock Snapshot, Support & Resistance, Technical Analysis buttons
  - ðŸŽ¯ **Smart Ticker Detection** - Automatic extraction from conversation context
  - â³ **Real-time Loading States** - Step-by-step progress feedback during analysis
  - ðŸ›¡ï¸ **Advanced Error Handling** - User-friendly error messages and recovery
  - ðŸ“ˆ **Enhanced Data Display** - Structured tables with confidence scoring
  - ðŸ” **Debug Monitoring** - FSM state tracking and troubleshooting info

- The app will print a local URL (default `http://127.0.0.1:7860`) to open in your browser.
- Pricing env vars (set in `.env`) will be used for cost estimates just like the CLI.

Environment variables:

- `OPENAI_MODEL` (optional, default `gpt-5-nano`)
- `HOST` and `PORT` to override GUI host/port

---

## Pricing and Cost Estimates

Set these optional env vars to compute accurate cost estimates (USD per 1M tokens):

```env
# Example values below â€” update with current OpenAI pricing for gpt-5-nano
OPENAI_GPT5_NANO_INPUT_PRICE_PER_1M=0.10
OPENAI_GPT5_NANO_OUTPUT_PRICE_PER_1M=0.40
```

At the end of each request, the CLI prints:

- Per message: input tokens, output tokens, input cost, output cost
- Session cumulative totals across the current run

Example snippet:

```text
Per Message Usage & Cost:
  - Input tokens: 1,234 | Input cost: $0.000123
  - Output tokens: 2,345 | Output cost: $0.000938
  - Message total cost: $0.001061

Session Total (Cumulative):
  - Total input tokens: 8,765 | Total input cost: $0.000877
  - Total output tokens: 9,876 | Total output cost: $0.003950
  - Session total cost: $0.004827
```

---

## Example Usage

```text
> Tesla price now
âœ” Query processed successfully!
Agent Response:
$TSLA is currently trading at $XXX.XX (as of 2024-06-07 15:30:00 UTC).
---------------------

> exit
Goodbye!
```

For reference, this is the system prompt used with every query:

```text
system_prompt=(
    "You are an expert financial analyst. Note that when using Polygon tools, prices are already stock split adjusted. "
    "Use the latest data available. Always double check your math. "
    "For any questions about the current date, use the 'get_today_date' tool. "
    "For long or complex queries, break the query into logical subtasks and process each subtask in order."
)
```

Be speficific in your prompt. The better the prompt - the better the response.

---

## Project Structure

The project has been organized into logical directories for improved maintainability:

```
market-parser-polygon-mcp/
â”œâ”€â”€ src/                          # Core application modules
â”‚   â”œâ”€â”€ response_parser.py        # Response parsing utilities  
â”‚   â”œâ”€â”€ json_parser.py           # JSON parsing with fallback strategies
â”‚   â”œâ”€â”€ json_schemas.py          # Schema definitions and validation
â”‚   â”œâ”€â”€ prompt_templates.py      # Structured prompt templates
â”‚   â”œâ”€â”€ schema_validator.py      # Validation logic and business rules
â”‚   â”œâ”€â”€ json_debug_logger.py     # Debug logging for workflows
â”‚   â”œâ”€â”€ security_utils.py        # Input validation and security
â”‚   â””â”€â”€ example_json_responses.py # Test examples and development aids
â”œâ”€â”€ stock_data_fsm/              # Finite State Machine for GUI workflow
â”‚   â”œâ”€â”€ states.py                # Application states and context
â”‚   â”œâ”€â”€ transitions.py           # State transition rules
â”‚   â”œâ”€â”€ manager.py               # FSM controller and orchestration
â”‚   â””â”€â”€ tests/                   # FSM-specific test suite
â”œâ”€â”€ tests/                       # Comprehensive test suite
â”‚   â”œâ”€â”€ test_integration.py      # Integration tests
â”‚   â”œâ”€â”€ test_production_*.py     # Production scenario validation
â”‚   â”œâ”€â”€ run_*.py                 # Test runners and scripts
â”‚   â””â”€â”€ validate_*.py            # Fix validation scripts
â”œâ”€â”€ logs/                        # Application and debug logs
â”œâ”€â”€ scripts/                     # Utility and demonstration scripts
â”œâ”€â”€ config/                      # Configuration files (future use)
â”œâ”€â”€ docs/                        # Comprehensive documentation
â”‚   â”œâ”€â”€ reports/                 # Technical reports and analysis
â”‚   â””â”€â”€ *.md                     # Architecture guides and user docs
â”œâ”€â”€ images/                      # Project assets
â”œâ”€â”€ market_parser_demo.py        # CLI application entry point
â”œâ”€â”€ chat_ui.py                   # Web GUI application
â””â”€â”€ pyproject.toml              # Project configuration
```

**Key Benefits of New Structure:**
- **Modularity**: Core logic separated into `src/` directory
- **Testing**: All tests consolidated in `tests/` directory  
- **Documentation**: Organized in `docs/` with dedicated `reports/` subfolder
- **Maintenance**: Utility scripts and logs properly organized
- **Scalability**: Ready for future configuration management

---

## Troubleshooting

- **Missing API Key:**

  If you see an error about `POLYGON_API_KEY` or `OPENAI_API_KEY`, make sure your `.env` file is in the project root.

- **Dependencies:**

  If you get `ModuleNotFoundError`, make sure your `pyproject.toml` lists:
  - `python-dotenv`
  - `rich`
  - `pydantic-ai-slim[openai]`
  - `gradio`

  If you prefer, you can use pip instead:

  ```sh
  pip install python-dotenv rich "pydantic-ai-slim[openai]" gradio
  python market_parser_demo.py
  ```

- **Import Errors with New Structure:**

  With the reorganized structure, update imports to use the new paths:
  ```python
  # New import patterns:
  from src.response_parser import ResponseParser
  from src.prompt_templates import PromptTemplateManager
  from stock_data_fsm.states import AppState
  ```

- **Test Execution:**

  Run tests from the project root using the new structure:
  ```sh
  # All tests
  uv run pytest tests/
  
  # Specific test files
  uv run pytest tests/test_integration.py
  
  # Production tests
  uv run python tests/run_production_tests.py
  ```

- **Incorrect Responses**

  AI Data can be incorrect. Like all LLM generated responses, please double check.

- **Other errors:**

  All errors are printed in red in the terminal for easy debugging.

---

## Analysis Tools Available

This project includes structured analysis and research capabilities for development:

### Systematic Analysis
- **Purpose**: Break down complex problems into manageable steps
- **Approach**: Methodical problem analysis using structured thinking patterns
- **Usage**: Required for all specialist agents before implementation

### Documentation Research
- **Purpose**: Research current best practices and implementation patterns
- **Sources**: Existing project documentation, industry standards, framework documentation
- **Focus**: Technology-specific patterns, security considerations, performance optimization

### Code Pattern Analysis
- **Purpose**: Analyze existing codebase patterns and architectural decisions
- **Benefits**: Maintain consistency, preserve architectural integrity, identify improvement opportunities
- **Application**: Used for refactoring, feature additions, and technical debt assessment

---

## Development Commands

### Running the Application

- **CLI interface**: `uv run market_parser_demo.py`
- **Web GUI interface**: `uv run chat_ui.py` (opens at <http://127.0.0.1:7860>)

### Testing

- **Run all tests**: `uv run pytest tests/` (pytest is in dev dependencies)
- **Run specific test**: `uv run pytest tests/test_file.py`
- **Run integration tests**: `uv run pytest tests/test_*integration*.py`
- **Run production tests**: `uv run python tests/run_production_tests.py`
- **Install dev dependencies**: `uv install --dev`

### Environment Management

- **Install dependencies**: `uv install`
- **Update dependencies**: `uv lock --upgrade`
- **Check environment**: `uv --version` and verify `.env` file exists

---

## How it Works

- Loads your Polygon and OpenAI API keys from `.env`
- Starts the Polygon MCP server in the background
- Provides structured analysis and research capabilities for development tasks
- Sends your natural language query to OpenAI `gpt-5-nano` via PydanticAI (OpenAI Responses API)
- Prints the answer in a readable format (CLI) or in a chat (GUI)

---

## Local Path

- /mnt/d/Github/market-parser-polygon-mcp

## License

This project is licensed under the [MIT License](LICENSE).